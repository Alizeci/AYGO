{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: BUILD A RAG USING LANGCHAIN AND OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.12/site-packages (1.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openai==0.28 in ./.venv/lib/python3.12/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in ./.venv/lib/python3.12/site-packages (from openai==0.28) (2.32.3)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from openai==0.28) (4.67.0)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.12/site-packages (from openai==0.28) (3.11.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests>=2.20->openai==0.28) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->openai==0.28) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->openai==0.28) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp->openai==0.28) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp->openai==0.28) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->openai==0.28) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->openai==0.28) (1.18.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain in ./.venv/lib/python3.12/site-packages (0.3.10)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.12/site-packages (from langchain) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.12/site-packages (from langchain) (3.11.7)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.22 in ./.venv/lib/python3.12/site-packages (from langchain) (0.3.22)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in ./.venv/lib/python3.12/site-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./.venv/lib/python3.12/site-packages (from langchain) (0.1.145)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in ./.venv/lib/python3.12/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.venv/lib/python3.12/site-packages (from langchain) (2.10.1)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./.venv/lib/python3.12/site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.22->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.22->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.22->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.22->langchain) (3.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain-core in ./.venv/lib/python3.12/site-packages (0.3.22)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.12/site-packages (from langchain-core) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.12/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in ./.venv/lib/python3.12/site-packages (from langchain-core) (0.1.145)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.12/site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in ./.venv/lib/python3.12/site-packages (from langchain-core) (2.10.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.12/site-packages (from langchain-core) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.12/site-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (3.10.11)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.27.1)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (1.0.7)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (3.10)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core) (2.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pinecone\n",
      "  Obtaining dependency information for pinecone from https://files.pythonhosted.org/packages/2a/16/169e969df341a32f6d1d9ace6f658b2d0ace3af11ae9294e29925c8c5f09/pinecone-5.4.1-py3-none-any.whl.metadata\n",
      "  Downloading pinecone-5.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in ./.venv/lib/python3.12/site-packages (from pinecone) (2024.8.30)\n",
      "Collecting pinecone-plugin-inference<4.0.0,>=2.0.0 (from pinecone)\n",
      "  Obtaining dependency information for pinecone-plugin-inference<4.0.0,>=2.0.0 from https://files.pythonhosted.org/packages/23/01/1e04d355f3966feb779cfccc2b84134087e91787196fdc6dc1e5747eaf56/pinecone_plugin_inference-3.0.0-py3-none-any.whl.metadata\n",
      "  Downloading pinecone_plugin_inference-3.0.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in ./.venv/lib/python3.12/site-packages (from pinecone) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./.venv/lib/python3.12/site-packages (from pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in ./.venv/lib/python3.12/site-packages (from pinecone) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in ./.venv/lib/python3.12/site-packages (from pinecone) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in ./.venv/lib/python3.12/site-packages (from pinecone) (2.2.3)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.5.3->pinecone) (1.16.0)\n",
      "Downloading pinecone-5.4.1-py3-none-any.whl (427 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.3/427.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pinecone_plugin_inference-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.7/87.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pinecone-plugin-inference, pinecone\n",
      "  Attempting uninstall: pinecone-plugin-inference\n",
      "    Found existing installation: pinecone-plugin-inference 1.1.0\n",
      "    Uninstalling pinecone-plugin-inference-1.1.0:\n",
      "      Successfully uninstalled pinecone-plugin-inference-1.1.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pinecone-client 5.0.1 requires pinecone-plugin-inference<2.0.0,>=1.0.3, but you have pinecone-plugin-inference 3.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pinecone-5.4.1 pinecone-plugin-inference-3.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv\n",
    "%pip install openai==0.28\n",
    "%pip install langchain\n",
    "%pip install -U langchain-core\n",
    "%pip install pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba de conexión básica con OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta: I'm sorry, but\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "try:\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": \"Test API key\"}],\n",
    "        max_tokens=5\n",
    "    )\n",
    "    print(\"Respuesta:\", response['choices'][0]['message']['content'].strip())\n",
    "except openai.error.AuthenticationError:\n",
    "    print(\"Error: La API Key no es válida o no está configurada correctamente.\")\n",
    "except openai.error.OpenAIError as e:\n",
    "    print(f\"Error al conectar con la API: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba de integración LangChain con OpenAI para generar respuestas basadas en una base de conocimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ql/j31d4jwd3n9bq05wmv6whz140000gn/T/ipykernel_61251/51267402.py:14: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n",
      "/var/folders/ql/j31d4jwd3n9bq05wmv6whz140000gn/T/ipykernel_61251/51267402.py:20: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Cargar variables de entorno\n",
    "load_dotenv()\n",
    "api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Inicializar el modelo de lenguaje\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    openai_api_key=api_key\n",
    ")\n",
    "\n",
    "# Inicializar embeddings de OpenAI\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "\n",
    "# Cargar y dividir el contenido\n",
    "loader = WebBaseLoader(\"https://www.escuelaing.edu.co/es/programas/maestria-en-informatica/\")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta: ¿Por qué estudiar Maestría en Informática?\n",
      "Respuesta: content='La Maestría en Informática de la Universidad Escuela Colombiana de Ingeniería Julio Garavito ofrece una oportunidad única para profundizar en los conocimientos computacionales y en la infraestructura para procesar y analizar datos. Este programa responde a las crecientes necesidades técnicas relacionadas con el uso eficiente de las Tecnologías de la Información y la Comunicación (TIC) y la protección de los datos. Entre las principales razones para estudiar esta maestría se encuentran:\\n\\n1. Crecimiento exponencial de los datos: Los datos están creciendo a un ritmo acelerado y necesitan ser procesados eficientemente. Esta maestría proporciona las habilidades necesarias para manejar grandes volúmenes de datos y extraer información útil de ellos.\\n\\n2. Alta demanda de software eficiente y de calidad: La maestría enseña cómo desarrollar software que sea eficiente, efectivo y de alta calidad. Los graduados estarán bien equipados para satisfacer la demanda de software de alta calidad en la industria.\\n\\n3. Amenazas cibernéticas: Con el aumento de las amenazas cibernéticas, es crucial proteger los datos y la información. La maestría en Informática ofrece formación en ciberseguridad, lo que permite a los graduados proteger a las organizaciones contra estas amenazas.\\n\\n4. Excelente calidad educativa: La universidad ofrece una educación de alta calidad, con una combinación de teoría, prácticas en laboratorios de última tecnología, casos prácticos y experiencia docente en las áreas de profundización del programa e investigación aplicada.\\n\\nEstudiar la Maestría en Informática en la Universidad Escuela Colombiana de Ingeniería Julio Garavito permitirá a los estudiantes convertirse en agentes de cambio en sus organizaciones y en la industria en general.' additional_kwargs={} response_metadata={'token_usage': <OpenAIObject at 0x10feafc50> JSON: {\n",
      "  \"prompt_tokens\": 1167,\n",
      "  \"completion_tokens\": 414,\n",
      "  \"total_tokens\": 1581,\n",
      "  \"prompt_tokens_details\": {\n",
      "    \"cached_tokens\": 0,\n",
      "    \"audio_tokens\": 0\n",
      "  },\n",
      "  \"completion_tokens_details\": {\n",
      "    \"reasoning_tokens\": 0,\n",
      "    \"audio_tokens\": 0,\n",
      "    \"accepted_prediction_tokens\": 0,\n",
      "    \"rejected_prediction_tokens\": 0\n",
      "  }\n",
      "}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-5353e078-a682-4f88-9809-3fe0b287f00a-0'\n"
     ]
    }
   ],
   "source": [
    "# Using InMemoryVectorStore\n",
    "\n",
    "# Extraer texto de los documentos divididos\n",
    "document_texts = [doc.page_content for doc in all_splits]\n",
    "\n",
    "# Crear el vector store en memoria y cargar documentos\n",
    "vector_store = InMemoryVectorStore.from_texts(\n",
    "    texts=document_texts,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "# Definir la plantilla del prompt\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=(\n",
    "        \"Usa el siguiente contexto para responder la pregunta:\\n\"\n",
    "        \"{context}\\n\\n\"\n",
    "        \"Pregunta: {question}\\n\"\n",
    "        \"Respuesta:\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Función para recuperar contexto y generar respuesta\n",
    "def retrieve_and_answer(question):\n",
    "    # Buscar documentos relevantes\n",
    "    retrieved_docs = vector_store.similarity_search(question, k=5)\n",
    "    \n",
    "    # Extraer el contenido de cada documento\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    \n",
    "    # Formatear el prompt\n",
    "    prompt = prompt_template.format(context=context, question=question)\n",
    "    \n",
    "    # Generar respuesta\n",
    "    response = llm.invoke(prompt)\n",
    "    return response\n",
    "\n",
    "# Probar la implementación\n",
    "question = \"¿Por qué estudiar Maestría en Informática?\"\n",
    "answer = retrieve_and_answer(question)\n",
    "print(\"Pregunta:\", question)\n",
    "print(\"Respuesta:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Por qué estudir Maestría en Informática?\n",
      "Answer: content='Estudiar la Maestría en Informática en la Universidad Escuela Colombiana de Ingeniería Julio Garavito tiene varios beneficios. Primero, responde a las necesidades técnicas actuales relacionadas con el uso eficiente de las TIC y la protección de los datos. En este sentido, prepara a los estudiantes para enfrentar el crecimiento exponencial de los datos y la alta demanda de software eficiente y de calidad. Además, aborda la aparición y aumento de amenazas cibernéticas que afectan a personas, organizaciones y gobiernos en el mundo. \\n\\nPor otro lado, la universidad tiene una reconocida experiencia de 30 años en ingeniería de sistemas y áreas afines, y hace aproximadamente 10 años que se investiga en el área de ciberseguridad, ingeniería de software, análisis de datos, big data e inteligencia de negocios. \\n\\nFinalmente, el programa forma a los estudiantes como agentes de cambio, profundizando en los conocimientos computacionales, la infraestructura para procesar y analizar datos, y el aseguramiento de la información de las organizaciones. Esto se logra a través de una educación teórica de excelente calidad, prácticas en laboratorios con tecnología de punta, casos prácticos y experiencia docente en las áreas de profundización del programa e inmersión en investigación aplicada.' additional_kwargs={} response_metadata={'token_usage': <OpenAIObject at 0x12afd59a0> JSON: {\n",
      "  \"prompt_tokens\": 974,\n",
      "  \"completion_tokens\": 304,\n",
      "  \"total_tokens\": 1278,\n",
      "  \"prompt_tokens_details\": {\n",
      "    \"cached_tokens\": 0,\n",
      "    \"audio_tokens\": 0\n",
      "  },\n",
      "  \"completion_tokens_details\": {\n",
      "    \"reasoning_tokens\": 0,\n",
      "    \"audio_tokens\": 0,\n",
      "    \"accepted_prediction_tokens\": 0,\n",
      "    \"rejected_prediction_tokens\": 0\n",
      "  }\n",
      "}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-5d5368a0-05c0-4bb7-ad1c-a71b6f1bb43f-0'\n"
     ]
    }
   ],
   "source": [
    "# Using FAISS\n",
    "\n",
    "# Create a FAISS VectorStore for indexing\n",
    "vector_store = FAISS.from_documents(all_splits, embeddings)\n",
    "\n",
    "# Define a question-answering prompt\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=(\n",
    "        \"Use the following context to answer the question:\\n\"\n",
    "        \"{context}\\n\\n\"\n",
    "        \"Question: {question}\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    ")\n",
    "\n",
    "def retrieve_and_answer(question):\n",
    "    retrieved_docs = vector_store.similarity_search(question, k=5)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    \n",
    "    prompt = prompt_template.format(context=context, question=question)\n",
    "    \n",
    "    # Generate response\n",
    "    response = llm.invoke(prompt)\n",
    "    return response\n",
    "\n",
    "# Test the implementation\n",
    "question = \"Por qué estudir Maestría en Informática?\"\n",
    "answer = retrieve_and_answer(question)\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de Arquitectura del RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción General\n",
    "La arquitectura tiene 4 partes:\n",
    "\n",
    "1. **Carga y preprocesamiento de datos:** Se cargan documentos desde una fuente web y se dividen en fragmentos manejables.\n",
    "2. **Embeddings e indexación:** Los fragmentos de texto se transforman en embeddings (representaciones vectoriales) y se almacenan en InMemoryVectorStore para búsquedas eficientes.\n",
    "3. **Procesamiento de consultas:** Las consultas del usuario se convierten en embeddings y se usan para recuperar los fragmentos más relevantes.\n",
    "4. **Generación de respuestas:** Una plantilla de prompt combina el contexto recuperado con la consulta del usuario para generar una respuesta utilizando GPT-4.\n",
    "\n",
    "\n",
    "\n",
    "## Flujo Completo de la Consulta\n",
    "\n",
    "- Consulta del Usuario: El usuario pregunta: \"¿Por qué estudiar Maestría en Informática?\"\n",
    "- Embedding de la Consulta: La consulta se convierte en un vector mediante OpenAIEmbeddings.\n",
    "- Recuperación: Se busca el embedding de la consulta en InMemoryVectorStore para identificar los 5 fragmentos más relevantes.\n",
    "- Construcción del Prompt: \n",
    "    - Los fragmentos recuperados se combinan en un contexto.\n",
    "    - El contexto y la consulta se insertan en la plantilla del prompt.\n",
    "- Generación de Respuesta: El prompt se envía a GPT-4, que genera una respuesta basada en el contexto proporcionado.\n",
    "- Resultado: La respuesta se muestra al usuario.\n",
    "\n",
    "\n",
    "## Consideraciones\n",
    "\n",
    "**InMemoryVectorStore** almacena todo en memoria, lo que lo hace inadecuado para conjuntos de datos muy grandes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: CONNECT THE RAG TO PINECONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinecone in ./.venv/lib/python3.12/site-packages (5.4.1)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in ./.venv/lib/python3.12/site-packages (from pinecone) (2024.8.30)\n",
      "Requirement already satisfied: pinecone-plugin-inference<4.0.0,>=2.0.0 in ./.venv/lib/python3.12/site-packages (from pinecone) (3.0.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in ./.venv/lib/python3.12/site-packages (from pinecone) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./.venv/lib/python3.12/site-packages (from pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in ./.venv/lib/python3.12/site-packages (from pinecone) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in ./.venv/lib/python3.12/site-packages (from pinecone) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in ./.venv/lib/python3.12/site-packages (from pinecone) (2.2.3)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.5.3->pinecone) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta: ¿Por qué estudiar Maestría en Informática?\n",
      "Respuesta: content='Estudiar una Maestría en Informática puede proporcionar una serie de beneficios. Primero, puede ayudar a profundizar tus conocimientos en áreas específicas de la informática, como la inteligencia artificial, la ciberseguridad, la ciencia de datos, entre otras. Esto puede abrirte la puerta a roles de trabajo más especializados y potencialmente más lucrativos. Además, un título de maestría puede hacer que te destaques en un campo competitivo, lo que podría aumentar tus posibilidades de conseguir un trabajo. También puede proporcionarte las habilidades necesarias para realizar investigaciones en el campo de la informática, lo cual es particularmente útil si estás interesado en un doctorado o una carrera en la academia.' additional_kwargs={} response_metadata={'token_usage': <OpenAIObject at 0x1279664e0> JSON: {\n",
      "  \"prompt_tokens\": 35,\n",
      "  \"completion_tokens\": 162,\n",
      "  \"total_tokens\": 197,\n",
      "  \"prompt_tokens_details\": {\n",
      "    \"cached_tokens\": 0,\n",
      "    \"audio_tokens\": 0\n",
      "  },\n",
      "  \"completion_tokens_details\": {\n",
      "    \"reasoning_tokens\": 0,\n",
      "    \"audio_tokens\": 0,\n",
      "    \"accepted_prediction_tokens\": 0,\n",
      "    \"rejected_prediction_tokens\": 0\n",
      "  }\n",
      "}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-18d56bd0-e58b-4337-b07c-3a036a5e53af-0'\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "from langchain.vectorstores import Pinecone as LangChainPinecone\n",
    "\n",
    "pinecode_api_key = os.environ[\"PINECONE_API_KEY\"]\n",
    "pc = Pinecone(api_key=pinecode_api_key)\n",
    "pinecone_index_name = \"langchain-rag-aygo\"\n",
    "\n",
    "pinecone_index = pc.Index(pinecone_index_name)\n",
    "\n",
    "# Crear el vector store con Pinecone y agregar documentos\n",
    "vector_store = LangChainPinecone.from_documents(\n",
    "    documents=all_splits,\n",
    "    embedding=embeddings,\n",
    "    index_name=pinecone_index_name\n",
    ")\n",
    "\n",
    "# Definir la plantilla del prompt\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=(\n",
    "        \"Usa el siguiente contexto para responder la pregunta:\\n\"\n",
    "        \"{context}\\n\\n\"\n",
    "        \"Pregunta: {question}\\n\"\n",
    "        \"Respuesta:\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Función para recuperar contexto y generar respuesta\n",
    "def retrieve_and_answer(question):\n",
    "\n",
    "    retrieved_docs = vector_store.similarity_search(question, k=5)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    prompt = prompt_template.format(context=context, question=question)\n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Probar la implementación\n",
    "question = \"¿Por qué estudiar Maestría en Informática?\"\n",
    "answer = retrieve_and_answer(question)\n",
    "print(\"Pregunta:\", question)\n",
    "print(\"Respuesta:\", answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicación de los Cambios\n",
    "\n",
    "- **Uso de Pinecone como Almacenamiento Vectorial:**\n",
    "    - Los documentos se almacenan en Pinecone, que permite búsquedas rápidas utilizando vectores de embeddings.\n",
    "    - Reemplaza el uso de almacenamiento en memoria, haciéndolo más escalable y persistente.\n",
    "- **Conexión a un Índice Existente:**\n",
    "    - Se utiliza Pinecone.Index para conectar al índice de Pinecone previamente creado.\n",
    "    - Esto asegura que los documentos se guarden y se recuperen en un entorno persistente.\n",
    "- **Integración con LangChain:**\n",
    "    - LangChainPinecone.from_documents utiliza los embeddings para almacenar documentos en Pinecone.\n",
    "    - Se proporciona el índice existente y los embeddings generados.\n",
    "- **Búsqueda de Similitud:** similarity_search realiza búsquedas eficientes en Pinecone, recuperando documentos relevantes para una consulta dada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaciones\n",
    "\n",
    "| **Aspecto**                | **InMemoryVectorStore**                           | **Pinecone**                                       |\n",
    "|----------------------------|--------------------------------------------------|--------------------------------------------------|\n",
    "| **Persistencia**            | No, los datos se pierden al finalizar el programa. | Sí, los datos permanecen guardados en el índice. |\n",
    "| **Escalabilidad**           | Limitado a la memoria del sistema.                | Alta, maneja grandes volúmenes de datos.         |\n",
    "| **Velocidad de Búsqueda**   | Muy rápida para conjuntos pequeños (en memoria).  | Rápida para conjuntos grandes (basado en red).   |\n",
    "| **Tiempo de Configuración** | Bajo, no requiere configuración adicional.        | Moderado, necesita inicialización y configuración del índice. |\n",
    "| **Dependencia de Red**      | No, funciona localmente.                          | Sí, requiere conexión a Pinecone.               |\n",
    "| **Latencia Promedio**       | ~0.01 - 0.05 segundos (para 1,000 documentos).     | ~0.2 - 0.5 segundos (para 1,000 documentos).     |\n",
    "| **Capacidad de Consulta**   | Limitada a la memoria y rendimiento local.         | Escalable, permite consultas concurrentes.       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consideraciones\n",
    "\n",
    "- **Latencia Promedio:**\n",
    "    - InMemoryVectorStore tiene ventaja para conjuntos pequeños debido a la naturaleza local de la memoria.\n",
    "    - Pinecone tiene una ligera latencia debido a la consulta a la red, pero se mantiene eficiente para grandes volúmenes.\n",
    "- **Escalabilidad:**\n",
    "    - Pinecone es ideal para aplicaciones que manejan miles o millones de documentos.\n",
    "    - InMemoryVectorStore se limita por la memoria del sistema y no escala bien.\n",
    "- **Uso Recomendado:**\n",
    "    - InMemoryVectorStore: Útil para prototipos o pruebas locales con pequeños conjuntos de datos.\n",
    "    - Pinecone: Ideal para producción, manejo de datos persistentes y aplicaciones de alto rendimiento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
